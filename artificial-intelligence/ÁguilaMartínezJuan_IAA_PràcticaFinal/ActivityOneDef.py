# -*- coding: utf-8 -*-"""@author: Juan Águila Martínez (UOC - 2015)"""import numpy as npimport pylabimport matplotlib.pyplot as pltfrom sklearn.decomposition import PCAfrom matplotlib.ticker import NullFormatter#####################################################################             # Activitat 1###################################################################### Definim els paràmetres de centralitat i dispersió per a la primera variablemu1, sigma1 = 0.5, 0.2# i generem un array amb 1000 valors que segueixin una distribució normal# parametrada segons els valors anteriorss1 = np.random.normal(mu1, sigma1, 1000)# Representem el conjunt anterior en un histograma amb 30 bins # i grafiquem la funció de distribució normalcount, bins, ignored = plt.hist(s1, 30, normed=True)plt.plot(bins,          1/(sigma1 * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu1)**2 / (2 * sigma1**2) ),              linewidth=2, color='r')plt.title("Variable 1: X1~N(0.5, 0.2)")plt.show()# Seguim el mateix procediment per a la segona variablemu2, sigma2 = 4.5, 0.6s2 = np.random.normal(mu2, sigma2, 1000)count, bins, ignored = plt.hist(s2, 30, normed=True)plt.plot(bins,          1/(sigma2 * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu2)**2 / (2 * sigma2**2) ),              linewidth=2, color='r')plt.title("Variable 2: X2~N(4.5, 0.6)")plt.show()# La tercera variable es construeix com a combinació linea de la primeras3 = 3 * s1 + 1count, bins, ignored = plt.hist(s3, 30, normed=True)plt.title("Variable 3: 3 x X1 + 1")plt.show()# i la cuarta com a combinació lineal de la primera i la segonas4 = 2 * s1**2 + s2count, bins, ignored = plt.hist(s3, 30, normed=True)plt.title("Variable 4: 2 x X1^2 + X2")plt.show()# Finalment, utilitzem el mètode `concatenate` de la llibreria numpy per a # construir una matriu de dimensió 4x1000s = np.concatenate(([s1], [s2], [s3], [s4]), axis=0 ).T# En aquest punt, podem triar una combinació de variables per tal de # realitzar la seva representació combinadax = s3 # ORDENADESy = s4 # ABCISSESnullfmt = NullFormatter() # Aquest mètode eliminarà les variables dels ticks# Definicions pels eixosleft, width = 0.1, 0.65bottom, height = 0.1, 0.65bottom_h = left_h = left+width+0.02rect_scatter = [left, bottom, width, height]rect_histx = [left, bottom_h, width, 0.2]rect_histy = [left_h, bottom, 0.2, height]# Comencem amb la figura rectangularplt.figure(1, figsize=(10,10))axScatter = plt.axes(rect_scatter)axHistx = plt.axes(rect_histx)axHisty = plt.axes(rect_histy)axHistx.xaxis.set_major_formatter(nullfmt) axHisty.yaxis.set_major_formatter(nullfmt)# el gràfic de dispersió:axScatter.scatter(x, y)# determinem els límits estèticsbinwidth = 0.25xymax = np.max( [np.max(np.fabs(x)), np.max(np.fabs(y))] )lim = ( int(xymax/binwidth) + 1) * binwidthaxScatter.set_xlim( (-lim, lim) )axScatter.set_ylim( (-lim, lim) )bins = np.arange(-lim, lim + binwidth, binwidth)axHistx.hist(x, bins=bins)axHisty.hist(y, bins=bins, orientation='horizontal')axHistx.set_xlim( axScatter.get_xlim() )axHisty.set_ylim( axScatter.get_ylim() )# i mostrem el gràficplt.show()# Apliquem l'anàlisi de components principals, amb ncomponents = 2pca = PCA()pca.fit(s)# Imprimim la variància explicada per aquestes 2 componentsacumvar = [sum(pca.explained_variance_ratio_[:i+1]) for i in range(len(pca.explained_variance_ratio_))]print(list(zip(range(len(acumvar)), acumvar)))pylab.plot(pca.explained_variance_ratio_,'o-')pylab.show()print(pca.get_covariance())# Ara representarem la distribució en 2 componentsX_transf = pca.fit_transform(s)plt.scatter(X_transf[:,0], X_transf[:,1])plt.title('PCA based on the covariance matrix of the raw data')plt.show()# Realitzem el mateix exercici amb 4 variables indepedentsmu1, sigma1 = 0.5, 0.2t1 = np.random.normal(mu1, sigma1, 1000)mu2, sigma2 = 4.5, 0.6t2 = np.random.normal(mu2, sigma2, 1000)mu3, sigma3 = 2.5, 0.6t3 = np.random.normal(mu3, sigma3, 1000)mu4, sigma4 = 5, 0.8t4 = np.random.normal(mu4, sigma4, 1000)# En aquest punt, podem triar una combinació de variables per tal de # realitzar la seva representació combinadax = t3 # ORDENADESy = t4 # ABCISSESnullfmt = NullFormatter() # Aquest mètode eliminarà les variables dels ticksleft, width = 0.1, 0.65bottom, height = 0.1, 0.65rect_scatter = [left, bottom, width, height]plt.figure(1, figsize=(5,5))axScatter = plt.axes(rect_scatter)axScatter.scatter(x, y)xymax = np.max( [np.max(np.fabs(x)), np.max(np.fabs(y))] )lim = ( int(xymax/binwidth) + 1) * binwidthaxScatter.set_xlim( (-lim, lim) )axScatter.set_ylim( (-lim, lim) )plt.show()t = np.concatenate(([t1], [t2], [t3], [t4]), axis=0 ).T# Apliquem l'anàlisi de components principals, amb ncomponents = 2pca = PCA()pca.fit(t)# Imprimim la variància explicada per aquestes 2 componentsacumvar = [sum(pca.explained_variance_ratio_[:i+1]) for i in range(len(pca.explained_variance_ratio_))]print(list(zip(range(len(acumvar)), acumvar)))pylab.plot(pca.explained_variance_ratio_,'o-')pylab.show()print(pca.get_covariance())# Ara representarem la distribució en 2 componentsX_transf = pca.fit_transform(s)plt.scatter(X_transf[:,0], X_transf[:,1])plt.title('PCA based on the covariance matrix of the raw data')plt.show()